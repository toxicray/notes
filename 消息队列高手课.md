# 							消息队列高手课



## 消息队列概况



**学习消息队列，有哪些门槛？** 

基础技术知识和能力，例如： 

1. 熟练使用各种常用集合，比如：数组、链表、字典等； 
2. 掌握 Linux 系统的基础知识，会使用常用的命令；
3.  具备多线程、并发控制编程能力；
4. 编写过读写文件、通过网络收发数据的程序；
5. 能看懂最基本的 UML 图，包括类图、时序图等；
6. 了解最常用的几种设计模式和算法。

RocketMQ 官方文档： https://rocketmq.apache.org/docs/quick-start/ 

RocketMQ 中国开发者中心：http://rocketmq.cloud/zh-cn/ 

Kafka 官方文档： http://kafka.apache.org/documentation/

RabbitMQ 官方文档： https://www.rabbitmq.com/documentation.html 

![消息生态的全场景](C:\Users\tyrion\Desktop\notes\notes\消息生态的全场景.png)







## 一、MQ的使用场景

### 	MQ能解决什么问题

​		**我们使用mq主要是为了解决什么问题呢****

#### 		1,异步处理

​					对于某些业务无关的后续操作, 我们可以考虑使用mq来进行操作解耦

#### 	   2,流量控制

​					比如说秒杀业务这种,我们可以考虑直接将数据丢到mq, 避免请求直接打到服务后端

#### 		3,服务解耦

​			

### 	MQ会带来什么样的问题

1. 引入了mq会带来业务处理的时延问题
2. 增加了系统的复杂度,提高了维护成本和难度
3. 有可能产生数据不一致的问题



### 	应用场景

1. ​	原来系统的库存变动服务主要是通过mq为触发, 该部分的业务场景,确保库存数据能够不丢失即可,需求点:

   - 消息不丢失

   - 能够缓解数据库压力,避免风险

     数据库本身的时延问题是不存在问题,因为在线的销售不会有库存问题,只需要保存最终一致性即可

​	2,     mq大量的数据, 它本身其实也是可以当做一个缓存系统来进行使用,如果需要考虑消息的堆积, 那么推荐使用rocketmq,kafka,pulsar



### 思索:

##### 一、对于令牌桶限流,   本质上限流是一种思想, 自身是可以有很多种实现方式

1. ​	redis的限流,后续参照redis教程,   <<redis深度历险>>

2. ​    guava的单机限流, guavalimiter

3. ​     nginx的限流

   和限流类似的问题:  计数

   kafka+ flink实现精确的计数

   redis的INCR实现精确的计数

   redis的hyperLogLOG   实现模糊的计数, 比较适合进行网站的PV和UV的计数



##### 二、RDMA和DMA

​	DMA:   传统的DMA, DMA控制器啦控制硬件IO设备的数据传输, 这也是为什么我们在设置我们系统的并发线程数的时候需要考虑系统的整体IO占比

​	RDMA:  节省内存交换,直接将数据传入对应的存储区



​	当前的MQ吞吐量的瓶颈并不在本机的内存数据交换这块, 目前主要的瓶颈还是在于网络带宽或者磁盘的IO



##### 三,  数据库的数据同步

​	在之前的公司系统中, 不同的系统中数据刷新,对于这类的问题,一定需要注意消息的顺序会不会影响业务



​	

## 二,   MQ的选型

### 	MQ的基本要求

1. 消息的可靠传递：确保不丢消息； 
2. Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息；
3. 性能：具备足够好的性能，能满足绝大多数场景的性能要求。

### RabbitMQ:

1. 轻量级, 开箱即用
2. 消息的堆积处理较差, 如果消息堆积会导致RabbitMQ的性能急剧下降
3. erlang语言不好扩展



##### 	扩展一下:   延时队列和死信队列

### ROCKETMQ:

1. 低延时

2. 无明显的缺点, 周边组件的适配一般

   

   ##### 扩展一下: 可以实现分布式事务

### KAFKA:

1. ​	之前存在消息丢失的情况,现在已经基本避免
2. ​    因为消息存在批处理的设计, 消息数量没那么多的时候时延反而会更大, 也就是说kafka的实时性会相对比较差(批次的大小是可配的)



​      和大数据相关,或者未来可能使用到大数据的场景,建议使用kafka

​		kafka采用了大量的"批量和异步"的设计, 考虑的是整体吞吐量, 类似于过河坐船(摆渡)

​		rocketmq的延时会更短



## 三, MQ的主题和队列

​	

### 一,队列模型

​		早期的消息队列都是按照队列的数据结构来进行设计的, 符合FIFO原则,这样的设计会有以下的特点

1. 消息的顺序自然有序, 天然的保证了消息的有序性
2. 对于多个消费者, 每个消费者之间其实是竞争关系,消息 只能被一个消费者所消费
3. 为了满足将消息被多方调用,必须将消息投递到多个队列中,但是消费者的数量是不确定的, 以此方式来进行实现的话,  本质上其实是违背了解耦的设计初衷





### 二,发布订阅模式

​		在发布-订阅模式中, 所有的过程分为了三个角色

- 发布者(PUBLISHER)

- 主题(TOPIC)
- 订阅者(Subcriber)

其本质上和传统的mq没有区别, 只是解决一份数据能被多次消费的问题



### 三,主流MQ的消息模型

##### 1,RabbitMQ

​	rabbitmq是仍然在使用队列模型, 生产者只需要把消息投递到Exchange上, 交换机负责将消息按照规则投递到各个队列上, 变相的实现发布订阅的效果

##### 2,RocketMQ

目前的MQ为了保证消息不会在投递和消费的过程中丢失, 在生产端和消费端都是有 "请求-确认" 机制, 这样可以很好的保证消息传递过程中的可靠性, 但是也会带来一个问题, 对于消费者来讲上一条消息必须消费成功之后,才能进行下一条消息的消费,  否则会出现消息空洞, 违背了有序性的原则.

​		RocketMQ的每个topic会包含多个队列, 通过多个队列来实现多实例的并行生产和并行消费.

​		RocketMQ中, 订阅者的概念是通过消费组来体现, 每个消费组会消费主体中一份完整的消息, 组间的消费者不会有关联,   但是组内的多实例消费者会有竞争关系

​		Rocket会为每个消费组在每个队列上维护一个offset,   消息的丢失都是由于offset的处理有问题

##### 3,Kafka

​	和rocketmq的模型一模一样,只是在名称上交partition



## 四, 利用事务消息实现分布式事务







## 五,消息丢失

#### 丢失消息可能是三个阶段

1. 发送阶段, 消息异常处理(同步发送),    异步发送的消息需要在回调中处理好业务逻辑
2. 存储阶段, broker存储消息(刷盘), 需要持久化消息之后再返回确认
3. 消费阶段, 完成所有的业务逻辑之后,   然后将消息返回对应的确认码

#### 消息的验证

​	对消息添加拦截器,在拦截器中实现序列号的添加,后续基于序列号进行消息的比对



## 六,处理消费过程中的重复消息

#### 	服务质量层级

**At most once**: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什 么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使 用，比如每分钟上报一

次机房温度数据，可以接受数据少量丢失。 

**At least once**: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消 息，但是允许有少量重复消息出现。 

**Exactly once**：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重 复，这个是最高的等级(还是可能会存在消息的重复问题, ack失败的场景)



#### 幂等性

**幂等（Idempotence）** 本来是一个数学上的概念，它是这样定义的： 如果一个函数 f(x) 满足：f(f(x)) = f(x)，则函数 f(x) 满足幂等性



**At least once + 幂等消费 = Exactly once。**



#### 幂等的设计思路

1. 数据库的唯一约束
2. 对数据添加版本号,类似于乐观锁
3. 对数据设置全局的id,   问题可能比较大,   发号的问题,  校验状态的过程存在竞态条件



## 七,消息积压了如何处理



​		对于这种标准的生产者消费者模型而言,消息积压只有一种可能(MQ处理数据的能力远大于业务系统), 消费的速度小于生产的速度(短时间的积压是正常的,MQ本身也是具有削峰能力)

​		从消费的角度来说, 两种方式:

1.  纵向缩短业务的处理时间, 
2.  横向增加机器的性能或者采用多个消费者来进行处理



批量消费数据的问题:

- 消费端必须要有批处理能力
- 一旦某一条消费失败会带来什么样的问题
- 对于实时性要求不高的方能使用,否则在数据量较小的时候会存在延时较大的可能性



## 八,网关如何接收服务端的秒杀结果



#### 1,网关如何接收服务端的秒杀结果?







##### 日志详解:

https://www.kancloud.cn/kancloud/log-real-time-datas-unifying/58709